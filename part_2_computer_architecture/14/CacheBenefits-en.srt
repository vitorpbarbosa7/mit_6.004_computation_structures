0
00:00:00,000 --> 00:00:12,000
We are going to compare the behavior of 3 different cache configurations on a benchmark program to better understand the impact of the cache configuration on the performance of the benchmark.

1
00:00:12,000 --> 00:00:18,000
The first cache we will consider is a 64-line direct mapped cache.

2
00:00:18,000 --> 00:00:29,000
The second is a 2-way set associative cache that uses the LRU, or least recently used, replacement strategy, and has a total of 64 lines.

3
00:00:29,000 --> 00:00:38,000
The third is a 4-way set associative cache that uses the LRU replacement strategy, and also has a total of 64 lines.

4
00:00:38,000 --> 00:00:47,000
Note that all three caches have the same capacity in that they can store a total of 64 words of data.

5
00:00:47,000 --> 00:00:53,000
In a direct mapped cache any particular memory address maps to exactly one line in the cache.

6
00:00:53,000 --> 00:00:58,000
Let's assume that our data is 32 bits, or 4 bytes wide.

7
00:00:58,000 --> 00:01:11,000
This means that consecutive addresses are 4 bytes apart, so we treat the bottom two address bits as always being 00 so that our address is on a data word boundary.

8
00:01:11,000 --> 00:01:16,000
Next, we want to determine which cache line this particular address maps to.

9
00:01:16,000 --> 00:01:23,000
Since there are 64 lines in this cache, we need 6 bits to select one of the 64 lines.

10
00:01:23,000 --> 00:01:26,000
These 6 bits are called the index.

11
00:01:26,000 --> 00:01:36,000
In this example, the index is 000011, so this particular address maps to line 3 of the cache.

12
00:01:36,000 --> 00:01:44,000
The data that gets stored in the cache is the tag portion of the address of the line plus the 32 bits of data.

13
00:01:44,000 --> 00:01:51,000
The tag is used for comparison when checking if a particular address is in the cache or not.

14
00:01:51,000 --> 00:01:55,000
It uniquely identifies the particular memory address.

15
00:01:55,000 --> 00:02:02,000
In addition, each cache line has a valid bit that lets you know whether the data in the cache is currently valid or not.

16
00:02:02,000 --> 00:02:11,000
This is important upon startup because without this bit there is no way to know whether the data in the cache is garbage or real data.

17
00:02:11,000 --> 00:02:20,000
In a 2-way set associative cache, the cache is divided into 2 sets each with half the number of lines.

18
00:02:20,000 --> 00:02:23,000
So we have two sets with 32 lines each.

19
00:02:23,000 --> 00:02:30,000
Since there are only 32 lines, we now only need a 5 bit index to select the line.

20
00:02:30,000 --> 00:02:36,000
However, any given index can map to two distinct locations, one in each set.

21
00:02:36,000 --> 00:02:43,000
This also means that when the tag comparisons are done, two comparisons are required, one per set.

22
00:02:43,000 --> 00:02:49,000
In a 4-way set associative cache, the cache is divided into 4 sets each with 16 lines.

23
00:02:49,000 --> 00:02:54,000
The width of the index is now 4 bits to select the cache line.

24
00:02:54,000 --> 00:03:03,000
Here, selecting a line identifies one of 4 words as possible locations for reading or writing the associated data.

25
00:03:03,000 --> 00:03:13,000
This also implies that 4 tags need to be compared when trying to read from the cache to determine if the desired address is stored in the cache or not.

26
00:03:13,000 --> 00:03:22,000
The test program begins by defining a few constants, J, A, B, and N.

27
00:03:22,000 --> 00:03:27,000
J specifies the address where the program lives.

28
00:03:27,000 --> 00:03:34,000
A is the starting address of data region 1, and B is the starting address of data region 2.

29
00:03:34,000 --> 00:03:38,000
Finally, N specifies the size of the data regions.

30
00:03:38,000 --> 00:03:46,000
Since one word consists of 4 bytes, 16 bytes of data mean that there are 4 data elements per region.

31
00:03:46,000 --> 00:03:53,000
Next the assembler is told that the beginning of the program is at address 0x1000.

32
00:03:53,000 --> 00:04:02,000
The green rectangle identifies the outer loop, and the yellow rectangle identifies the inner loop of the code.

33
00:04:02,000 --> 00:04:09,000
Before entering the outer loop, a loop counter, which is stored in register R6 is initialized to 1,000.

34
00:04:09,000 --> 00:04:19,000
Then each time through the outer loop, R6 is decremented by 1 and the loop is repeated as long as R6 is not equal to 0.

35
00:04:19,000 --> 00:04:25,000
The outer loop also resets R0 to N each time through the loop.

36
00:04:25,000 --> 00:04:29,000
R0 is used to hold the desired array offset.

37
00:04:29,000 --> 00:04:38,000
Since the last element of the array is stored at location N -- 4, the first step of the inner loop, is to decrement R0 by 4.

38
00:04:38,000 --> 00:04:50,000
R1 is then loaded with the value at address A + N -- 4 which is the address of A[3] because array indeces begin at 0.

39
00:04:50,000 --> 00:04:54,000
R2 is loaded with B[3].

40
00:04:54,000 --> 00:05:06,000
As long as R0 is not equal to 0, the loop repeats itself, each time accessing the previous element of each array until the first element (index 0) is loaded.

41
00:05:06,000 --> 00:05:13,000
Then the outer loop decrements R6 and repeats the entire thing 1000 times.

42
00:05:13,000 --> 00:05:25,000
Now that we understand the configuration of our three caches and the behavior of our test benchmark, we can begin comparing the behavior of this benchmark on the three caches.

43
00:05:25,000 --> 00:05:33,000
The first thing we want to ask ourselves is which of the three cache configurations gets the highest hit ratio.

44
00:05:33,000 --> 00:05:43,000
Here we are not asked to calculate an actual hit ratio, instead we just need to realize that there are 3 distinct regions of data in this benchmark.

45
00:05:43,000 --> 00:05:51,000
The first holds the instructions, the second holds array A, and the third holds array B.

46
00:05:51,000 --> 00:06:00,000
If we think about the addresses of each of these regions in memory, we see that the first instruction is at address 0x1000.

47
00:06:00,000 --> 00:06:11,000
This will result in an index of 0 regardless of which cache you consider, so for all three caches the first instruction would map to the first line of the cache.

48
00:06:11,000 --> 00:06:21,000
Similarly the first element of arrays A and B are at address 0x2000 and 0x3000.

49
00:06:21,000 --> 00:06:28,000
These addresses will also result in an index of 0 regardless of which of the three caches you consider.

50
00:06:28,000 --> 00:06:36,000
So we see that the 1st CMOVE, A[0], and B[0] would all map to line 0 of the cache.

51
00:06:36,000 --> 00:06:50,000
Similarly, the 2nd CMOVE whose address is 0x1004 would map to line 1 of the cache as would array elements A[1] and B[1].

52
00:06:50,000 --> 00:07:02,000
This tells us that if we use the direct mapped cache, or a 2-way set associative cache, then we will have cache collisions between the instructions, and the array elements.

53
00:07:02,000 --> 00:07:09,000
Collisions in the cache imply cache misses as we replace one piece of data with another in the cache.

54
00:07:09,000 --> 00:07:23,000
However, if we use a 4-way set associative cache then each region of memory can go in a distinct set in the cache thus avoiding collisions and resulting in 100% hit rate after the first time through the loop.

55
00:07:23,000 --> 00:07:34,000
Note that the first time through the loop each instruction and data access will result in a cache miss because the data needs to initially be brought into the cache.

56
00:07:34,000 --> 00:07:40,000
But when the loop is repeated, the data is already there and results in cache hits.

57
00:07:40,000 --> 00:07:51,000
Now suppose that we make a minor modification to our test program by changing B from 0x3000 to 0x2000.

58
00:07:51,000 --> 00:07:58,000
This means that array A and array B now refer to same locations in memory.

59
00:07:58,000 --> 00:08:06,000
We want to determine, which of the cache's hit rate will show a noticeable improvement as a result of this change.

60
00:08:06,000 --> 00:08:18,000
The difference between our original benchmark and this modified one is that we now have two distinct regions of memory to access, one for the instructions, and one for the data.

61
00:08:18,000 --> 00:08:30,000
This means that the 2-way set associative cache will no longer experience collisions in its cache, so its hit rate will be significantly better than with the original benchmark.

62
00:08:30,000 --> 00:08:41,000
Now suppose that we change our benchmark once again, this time making J, A and B all equal to 0, and changing N to be 64.

63
00:08:41,000 --> 00:08:47,000
This means that we now have 16 elements in our arrays instead of 4.

64
00:08:47,000 --> 00:08:56,000
It also means that the array values that we are loading for arrays A and B are actually the same as the instructions of the program.

65
00:08:56,000 --> 00:09:03,000
Another way of thinking about this is that we now only have one distinct region of memory being accessed.

66
00:09:03,000 --> 00:09:10,000
What we want to determine now, is the total number of cache misses that will occur for each of the cache configurations.

67
00:09:10,000 --> 00:09:15,000
Let's begin by considering the direct mapped cache.

68
00:09:15,000 --> 00:09:21,000
In the direct mapped cache, we would want to first access the first CMOVE instruction.

69
00:09:21,000 --> 00:09:27,000
Since this instruction is not yet in the cache, our first access is a cache miss.

70
00:09:27,000 --> 00:09:33,000
We now bring the binary equivalent of this instruction into line 0 of our cache.

71
00:09:33,000 --> 00:09:37,000
Next, we want to access the second CMOVE instruction.

72
00:09:37,000 --> 00:09:44,000
Once again the instruction is not in our cache so we get another cache miss.

73
00:09:44,000 --> 00:09:50,000
This results in our loading the 2nd CMOVE instruction to line 1 of our  cache.

74
00:09:50,000 --> 00:09:57,000
We continue in the same manner with the SUBC instruction and the first LD instruction.

75
00:09:57,000 --> 00:10:06,000
Again we get cache misses for each of those instructions and that in turn causes us to load those instructions into our cache.

76
00:10:06,000 --> 00:10:10,000
Now, we are ready to execute our first load operation.

77
00:10:10,000 --> 00:10:15,000
This operation wants to load A[15] into R1.

78
00:10:15,000 --> 00:10:23,000
Because the beginning of array A is at address 0, then A[15] maps to line 15 of our cache.

79
00:10:23,000 --> 00:10:32,000
Since we have not yet loaded anything into line 15 of our cache, this means that our first data access is a miss.

80
00:10:32,000 --> 00:10:34,000
We continue with the second load instruction.

81
00:10:34,000 --> 00:10:42,000
This instruction is not yet in the cache, so we get a cache miss and then load it into line 4 of our cache.

82
00:10:42,000 --> 00:10:45,000
We then try to access B[15].

83
00:10:45,000 --> 00:10:57,000
B[15] corresponds to the same piece of data as A[15], so this data access is already in the cache thus resulting in a data hit for B[15].

84
00:10:57,000 --> 00:11:04,000
So far we have gotten 5 instruction misses, 1 data miss and 1 data hit.

85
00:11:04,000 --> 00:11:08,000
Next we need to access the BNE instruction.

86
00:11:08,000 --> 00:11:16,000
Once again we get a cache miss which results in loading the BNE instruction into line 5 of our cache.

87
00:11:16,000 --> 00:11:25,000
The inner loop is now repeated with R0 = 60 which corresponds to element 14 of the arrays.

88
00:11:25,000 --> 00:11:33,000
This time through the loop, all the instructions are already in the cache and result in instruction hits.

89
00:11:33,000 --> 00:11:42,000
A[14] which maps to line 14 of our cache results in a data miss because it is not yet present in our cache.

90
00:11:42,000 --> 00:11:45,000
So we bring A[14] into the cache.

91
00:11:45,000 --> 00:11:57,000
Then as before, when we try to access B[14], we get a data hit because it corresponds to the same piece of data as A[14].

92
00:11:57,000 --> 00:12:03,000
So in total, we have now seen 6 instruction misses and 2 data misses.

93
00:12:03,000 --> 00:12:07,000
The rest of the accesses have all been hits.

94
00:12:07,000 --> 00:12:30,000
This process repeats itself with a data miss for array element A[i], and a data hit for array element B[i] until we get to A[5] which actually results in a hit because it corresponds to the location in memory that holds the BNE(R0, R) instruction which is already in the cache at line 5.

95
00:12:30,000 --> 00:12:35,000
From then on the remaining data accesses all result in hits.

96
00:12:35,000 --> 00:12:42,000
At this point we have completed the inner loop and proceed to the remaining instructions in the outer loop.

97
00:12:42,000 --> 00:12:48,000
These instructions are the second SUBC and the second BNE instructions.

98
00:12:48,000 --> 00:12:55,000
These correspond to the data that is in lines 6 and 7 of the cache thus resulting in hits.

99
00:12:55,000 --> 00:13:06,000
The loop then repeats itself 1000 times but each time through all the instructions and all the data is in the cache so they all result in hits.

100
00:13:06,000 --> 00:13:14,000
So the total number of misses that we get when executing this benchmark on a direct mapped cache is 16.

101
00:13:14,000 --> 00:13:22,000
These are known as compulsory misses which are misses that occur when you are first loading the data into your cache.

102
00:13:22,000 --> 00:13:28,000
Recall that the direct mapped cache has one set of 64 lines in the cache.

103
00:13:28,000 --> 00:13:39,000
The 2-way set associative has 2 sets of 32 lines each, and the 4-way set associative has 4 sets of 16 lines each.

104
00:13:39,000 --> 00:14:12,000
Since only 16 lines are required to fit all the instructions and data associated with this benchmark, this means that effectively, only one set will be used in the set associative caches, and because even in the 4-way set associative cache there are 16 lines, that means that once the data is loaded into the cache it does not need to be replaced with other data so after the first miss per line, the remaining accesses in the entire benchmark will be hits.

105
00:14:12,000 --> 00:14:20,000
So the total number of misses in the 2-way and 4-way set associative caches is also 16.

